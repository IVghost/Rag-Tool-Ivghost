import threading
import time
import torch
import logging

# Event global pour stopper les opÃ©rations
stop_event = threading.Event()

# Configuration du logging
LOG_FILE = "nutricoach.log"
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
console.setFormatter(formatter)
logging.getLogger().addHandler(console)


def log(message: str) -> None:
    """Affiche un message dans le logger et dans la console"""
    logging.info(message)


def stop_operations() -> None:
    """DÃ©clenche l'arrÃªt des opÃ©rations en cours, vide le cache GPU et termine les threads."""
    stop_event.set()
    log(f"[{time.strftime('%H:%M:%S')}] ğŸ›‘ Demande d'arrÃªt reÃ§ue. Tentative de libÃ©ration des ressources...")

    try:
        # LibÃ©ration mÃ©moire GPU
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            log(f"[{time.strftime('%H:%M:%S')}] âœ… MÃ©moire GPU libÃ©rÃ©e.")
        else:
            log(f"[{time.strftime('%H:%M:%S')}] âš ï¸ Pas de GPU dÃ©tectÃ©, pas de mÃ©moire Ã  libÃ©rer.")

        # ArrÃªt des threads
        for thread in threading.enumerate():
            if thread.is_alive() and thread != threading.main_thread():
                log(f"[{time.strftime('%H:%M:%S')}] â³ Tentative d'arrÃªt du thread {thread.name}...")
                thread.join(timeout=1)

        log(f"[{time.strftime('%H:%M:%S')}] âœ… Tous les threads ont Ã©tÃ© arrÃªtÃ©s.")

    except Exception as e:
        log(f"[{time.strftime('%H:%M:%S')}] âŒ Erreur lors de l'arrÃªt des opÃ©rations : {e}")
